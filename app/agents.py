"""
M√≥dulo de Agentes Inteligentes (O C√©rebro)

Este m√≥dulo √© respons√°vel por definir a "intelig√™ncia" do sistema. Ele cont√©m:
1. LLMClient: Uma ponte que conecta nosso c√≥digo aos modelos de linguagem do Databricks (ex: Llama 3).
2. Agent: A classe que cria os "funcion√°rios digitais" (Log√≠stica, Finan√ßas, COO). 

Pense neste arquivo como o escrit√≥rio onde os agentes "pensam", recebem tarefas, consultam ferramentas 
e geram suas respostas. Cada agente tem uma personalidade (role) e acesso a um contexto espec√≠fico.
"""
from databricks_langchain import ChatDatabricks
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
import os

class LLMClient:
    def __init__(self):
        """
        Inicializa o LLMClient com um modelo Databricks espec√≠fico.
        
        Este cliente configura o modelo ChatDatabricks com par√¢metros pr√©-definidos 
        como temperatura e max tokens. Seleciona 'databricks-llama-4-maverick' 
        por padr√£o (√≠ndice 2).

        Entradas:
            Nenhuma

        Sa√≠das:
            Nenhuma (inicializa self.chat_model)
        """
        # Lista de modelos dispon√≠veis no Databricks
        models = [
            'databricks-gpt-oss-20b',
            'databricks-gpt-oss-120b',
            'databricks-llama-4-maverick',
            'databricks-gemma-3-12b',
            'databricks-meta-llama-3-1-8b-instruct',
            'databricks-meta-llama-3-3-70b-instruct',
            'databricks-gte-large-en',
            'databricks-meta-llama-3-1-405b-instruct'
        ]
        
        # Criar uma inst√¢ncia do modelo ChatDatabricks
        # O usu√°rio selecionou o index 2: databricks-llama-4-maverick
        self.chat_model = ChatDatabricks(
            endpoint=models[5],  
            temperature=0.1,
            max_tokens=5000
        )

    def completion(self, messages_list):
        """
        Envia mensagens para o LLM do Databricks e retorna o conte√∫do da resposta.
        
        Converte a lista de dicion√°rios (formato OpenAI) para objetos Message do LangChain 
        e invoca o modelo de chat do Databricks.

        Entradas:
            messages_list (list): Uma lista de dicion√°rios representando o hist√≥rico do chat.
                                  Cada dict deve ter 'role' ('system', 'user', 'assistant') 
                                  e 'content' (str).

        Sa√≠das:
            str: O conte√∫do em texto da resposta da IA. 
                 Retorna uma mensagem de erro se ocorrer uma exce√ß√£o.
        """
        langchain_messages = []
        for msg in messages_list:
            role = msg.get("role")
            content = msg.get("content")
            
            if role == "system":
                langchain_messages.append(SystemMessage(content=content))
            elif role == "user":
                langchain_messages.append(HumanMessage(content=content))
            elif role == "assistant":
                langchain_messages.append(AIMessage(content=content))
            else:
                # Fallback for other roles if any
                langchain_messages.append(HumanMessage(content=content))
        
        try:
            response = self.chat_model.invoke(langchain_messages)
            # response is an AIMessage object
            return response.content
        except Exception as e:
            return f"ERROR: Databricks LLM Interaction Failed: {str(e)}"

LOGISTICS_PROMPT = """
VOC√ä √â: Head de Log√≠stica e Supply Chain do E-commerce Olist.
PERSONALIDADE: Anal√≠tica, direta, obcecada por efici√™ncia.
MISS√ÉO: Reduzir Custo de Frete e eliminar Atrasos de Entrega.

‚ö†Ô∏è REGRAS DE OURO (ANTI-PATTERNS):
1. AN√ÅLISE APENAS DE PEDIDOS FINALIZADOS: Ignore pedidos 'processing', 'unavailable' ou com datas nulas.
2. SEM DESCULPAS: N√£o sugira "monitorar" ou "conversar". Dite a mudan√ßa no sistema.
3. FILTRO OBRIGAT√ìRIO: Use `WHERE order_delivered_customer_date IS NOT NULL` e `order_estimated_delivery_date IS NOT NULL` em todas as queries de atraso.

FERRAMENTAS:
Voc√™ tem acesso total ao SparkSQL. Use para validar suas hip√≥teses.
Tabelas: olist_dataset.olist_sales.orders, order_items, olist_logistics.customers...

FORMATO DE RESPOSTA (Siga estritamente):
1. üéØ DIAGN√ìSTICO DE DADOS
   - Qual o % de atraso? Qual a rota problem√°tica?
   - Mostre a Query SQL usada e o resultado.
2. üõ†Ô∏è A√á√ÉO DE ENGENHARIA
   - Ex: "Aumentar prazo de entrega no CEP X em 2 dias".
   - Ex: "Trocar transportadora na rota SP-RJ".
3. üìâ IMPACTO FINANCEIRO/OPERACIONAL
   - Ex: "Redu√ß√£o de 20% nos tickets de SAC".
"""

FINANCE_PROMPT = """
VOC√ä √â: Diretor Financeiro (CFO) do E-commerce Olist.
PERSONALIDADE: Conservadora, avessa a riscos, focada em Bottom-line.
MISS√ÉO: Garantir margem positiva e estancar sangria de caixa.

‚ö†Ô∏è REGRAS DE OURO (ANTI-PATTERNS):
1. DADOS T√ìXICOS: JAMAIS use a tabela `olist_cx.order_reviews`. Ela cont√©m texto sujo que quebra o SQL.
2. FOCO EM DINHEIRO: Use `order_payments`, `order_items` e `orders`.
3. SEM TEORIA: N√£o fale de conceitos abstratos. Mostre quanto dinheiro estamos perdendo.

L√ìGICA DE AN√ÅLISE:
- Cruze pedidos atrasados (Orders) com o valor pago (Payments) para saber o Revenue at Risk.
- Verifique se o parcelamento (installments) em itens baratos est√° comendo a margem.

FORMATO DE RESPOSTA (Siga estritamente):
1. üí∞ AUDITORIA FINANCEIRA (Com SQL)
   - Quanto dinheiro est√° em risco?
   - Mostre a query e o valor.
2. ‚úÇÔ∏è CORTE DE GASTOS/RISCO
   - Ex: "Bloquear parcelamento > 3x para Eletr√¥nicos".
   - Ex: "Aumentar shipping_cost para pedidos < R$ 50".
3. üìä RESULTADO ESPERADO
   - Ex: "Economia de R$ 150k/m√™s".
"""

COO_PROMPT = """
VOC√ä √â: Chief Operating Officer (COO) do E-commerce Olist.
PERSONALIDADE: Estrat√©gica, decisiva, vis√£o 360¬∫.
MISS√ÉO: Consolidar informa√ß√µes e dar o "Go/No-Go" final.

‚ö†Ô∏è REGRAS DE OURO:
1. N√ÉO SEJA T√âCNICO: N√£o discuta queries SQL ou erros de banco de dados.
2. DECIDA: Voc√™ √© a √∫ltima inst√¢ncia. Se Log√≠stica diz X e Finan√ßas diz Y, voc√™ decide Z.
3. OLHAR DE DONO: O que √© melhor para a empresa a longo prazo?

CONTEXTO:
Voc√™ recebeu relat√≥rios t√©cnicos dos seus diretores (Log√≠stica e Finan√ßas).
Sua tarefa √© sintetizar isso em um Plano de A√ß√£o Executivo.

FORMATO DE RESPOSTA (Corporativo):
1. üìã SITUA√á√ÉO (Executive Summary)
   - O que est√° acontecendo em 1 frase?
2. üöÄ DECIS√ÉO ESTRAT√âGICA
   - O que vamos fazer? (A√ß√£o concreta).
3. ‚ö° PR√ìXIMOS PASSOS IMEDIATOS
   - Ordens claras para os departamentos.
"""

AGENT_PROMPTS = {
    "logistics": LOGISTICS_PROMPT,
    "finance": FINANCE_PROMPT,
    "coo": COO_PROMPT
}

class Agent:
    def __init__(self, name, role, context_manager, tool=None, persona_instructions=None):
        """
        Inicializa um Agente com uma fun√ß√£o, contexto e ferramenta opcionais espec√≠ficos.

        Entradas:
            name (str): O nome do agente (ex: "LogisticsAgent").
            role (str): A fun√ß√£o do agente ('logistics', 'finance', 'coo').
            context_manager (ContextManager): Um gerenciador para recuperar informa√ß√µes de schema e contexto.
            tool (SparkSQLTool, opcional): Uma ferramenta para executar consultas SQL. Padr√£o √© None.
            persona_instructions (str, opcional): Instru√ß√µes detalhadas sobre a persona e comportamento do agente.

        Sa√≠das:
            Nenhuma
        """
        self.name = name
        self.role = role # 'logistics', 'finance', 'coo'
        self.context_manager = context_manager
        self.tool = tool
        self.persona_instructions = persona_instructions
        self.llm = LLMClient()
        self.history = []

    def run(self, task_input):
        """
        Executa o loop principal do agente para resolver uma tarefa dada.

        Este m√©todo constr√≥i o contexto inicial e o prompt do sistema, depois entra em um loop de 
        racioc√≠nio e a√ß√£o (similar ao ReAct). Ele envia o hist√≥rico para o LLM, analisa a 
        resposta em busca de consultas SQL (se uma ferramenta estiver dispon√≠vel), executa-as 
        e alimenta a sa√≠da de volta para o LLM at√© que uma resposta final seja alcan√ßada ou 
        o n√∫mero m√°ximo de turnos seja excedido.

        Entradas:
            task_input (str): A tarefa ou pergunta do usu√°rio para o agente.

        Sa√≠das:
            str: A resposta de texto final do agente (ou uma mensagem de timeout).
        """
        print(f"\\n--- Starting Agent: {self.name} ({self.role}) ---")
        
        # 1. Build Context
        schema_context = self.context_manager.get_schema_context(self.role)
        system_prompt = self._build_system_prompt(schema_context)
        
        self.history = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": task_input}
        ]

        # 2. Execution Loop (Reasoning + Tool Use)
        # We allow a few turns for self-healing
        max_turns = 20 
        
        for i in range(max_turns):
            response = self.llm.completion(self.history)
            
            if "ERROR:" in response and "OPENAI_API_KEY" in response:
                return response # Fail fast if no config

            print(f"Agent Thought: {response}")
            self.history.append({"role": "assistant", "content": response})

            # Check if agent wants to use Tool (simple heuristic: specific marker or sql code block)
            # For this custom implementation, we assume if the agent outputs SQL-like text, we run it.
            # OR we instruct the agent to output: QUERY: <sql>
            
            query = self._extract_query(response)
            
            if query and self.tool:
                tool_output = self.tool.run_query(query)
                self.history.append({"role": "user", "content": f"Tool Output: {tool_output}"})
                
                # Check if it was an error to encourage self-healing logic in next turn
                if "ERROR" in tool_output:
                    print("  -> Tool Error caught, retrying...")
                    continue # The LLM will see the error in history and retry
                else:
                    # If success, we might be done or need more analysis. 
                    # For simplicity, if we get data, we ask for final answer or just continue.
                    # As per instruction, the agent analyzes the data.
                    pass
            else:
                # If no query, assumption is the agent provided the final answer or analysis
                return response

        return "Agent timed out or failed to converge."

    def _build_system_prompt(self, schema_context):
        """
        Constr√≥i o prompt do sistema utilizando templates especializados por Agente.
        
        Em vez de um template gen√©rico, agora carregamos PROMPTS totalmente customizados 
        para Log√≠stica, Finan√ßas e COO, garantindo m√°xima relev√¢ncia no output.
        """
        # 1. Recupera o Prompt Especializado
        base_prompt = AGENT_PROMPTS.get(self.role, "Voc√™ √© um assistente IA √∫til.")
        
        # 2. Adiciona instru√ß√µes espec√≠ficas da tarefa (vindas do Orchestrator)
        # Isso permite que o Orquestrador d√™ um "norte" tempor√°rio sem quebrar a persona
        if self.persona_instructions:
            base_prompt += f"\n\n### FOCO ESPEC√çFICO DA TAREFA ATUAL:\n{self.persona_instructions}"
            
        # 3. Adiciona Schema de Dados se dispon√≠vel
        if schema_context:
            base_prompt += f"\n\n### MAPA DE DADOS (SCHEMA DISPON√çVEL):\n{schema_context}"
            
        return base_prompt

    def _extract_query(self, text):
        """
        Extrai c√≥digo SQL de blocos de c√≥digo markdown no texto.

        Entradas:
            text (str): A resposta de texto do LLM contendo potenciais blocos SQL.

        Sa√≠das:
            str ou None: A string da consulta SQL extra√≠da se encontrada, caso contr√°rio None.
        """
        if "```sql" in text:
            start = text.find("```sql") + 6
            end = text.find("```", start)
            return text[start:end].strip()
        return None